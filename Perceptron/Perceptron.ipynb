{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Linhas x Colunas (5572, 2) \n",
      "\n",
      "[nltk_data] Downloading package words to C:\\Users\\Luis\n",
      "[nltk_data]     Carlos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## DATA SETS ---------\n",
    "df = pd.read_csv(\"spam.csv\", encoding = \"latin-1\")\n",
    "df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1, inplace = True)\n",
    "\n",
    "## TRANSFORMS\n",
    "df.columns = [\"Status\", \"Mensagem\"]\n",
    "\n",
    "print(\"Linhas x Colunas\", df.shape, \"\\n\") \n",
    "df.head() \n",
    "\n",
    "\n",
    "nltk.download(\"words\")\n",
    "set_words = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            Mensagem Status\n",
       "0  go until jurong point  crazy   available only ...      0\n",
       "1                      ok lar    joking wif u oni         0\n",
       "2  free entry in 2 a wkly comp to win fa cup fina...      1\n",
       "3  u dun say so early hor    u c already then say         0\n",
       "4  nah i don t think he goes to usf  he lives aro...      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mensagem</th>\n      <th>Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>go until jurong point  crazy   available only ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ok lar    joking wif u oni</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>u dun say so early hor    u c already then say</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>nah i don t think he goes to usf  he lives aro...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df['Mensagem'] = df['Mensagem'].str.replace('\\W', ' ') # Limpa a pontuação\n",
    "df['Mensagem'] = df['Mensagem'].str.replace('subject', ' ') # Limpa o subject\n",
    "df['Mensagem'] = df['Mensagem'].str.lower()  #Transforma tudo em letra pequena\n",
    "\n",
    "df = df[[\"Mensagem\", \"Status\"]]\n",
    "\n",
    "df['Status']= df['Status'].map(str)\n",
    "df['Status'] = df['Status'].str.replace('spam', '1') # Limpa o subject\n",
    "df['Status'] = df['Status'].str.replace('ham', '0') # Limpa o subject\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ficheiro):                                   # Função train - Recebe um ficheiro e cria um dicionário (vocabulary) das \n",
    "    for i in range(df.shape[0]):                          # Ciclo que corre todas as mensagens do ficheiro\n",
    "        email = df.iloc[i, 0].split()                     # Mensagem separada por palavras\n",
    "\n",
    "        for word in email:                                  # Ciclo que corre todas as palavras de uma mensagem\n",
    "            if word.lower() not in vocabulary and word.lower() in set_words: # Verificação da existência da palavra no dicionário vocabulary e no set set_words\n",
    "                vocabulary[word] = len(vocabulary)          # Atribuição de uma posição à palavra analisada no dicionário vocabulary\n",
    "    generate(str(ficheiro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(ficheiro):                                # Função generate - Gera as matrizes data e verify\n",
    "    global data                                             # Variável data definida como global\n",
    "    data = np.zeros((df.shape[0], len(vocabulary)))       # Criação de uma matriz com número de linhas igual ao número de linhas do ficheiro e com número de colunas igual ao número de palavras (sem repetição) existentes no vocabulário\n",
    "    global verify                                           # Variável verify definida como global\n",
    "    verify = np.zeros(df.shape[0])                        # Criação de uma matriz com número de linhas igual ao número de linhas do ficheiro e com uma coluna\n",
    "\n",
    "    for i in range(df.shape[0]):                          # Ciclo que corre todas as linhas do ficheiro\n",
    "        email = df.iloc[i, 0].split()                     # Mensagem separada por palavras\n",
    "\n",
    "        for word in email:                                  # Ciclo que corre todas as palavras de uma mensagem\n",
    "            if word.lower() in vocabulary:                  # Verificação da existência da palavra no dicionário vocabulary\n",
    "                data[i, vocabulary[word]] += 1              # Adição de valores à matriz data (+1 no índice da palavra que foi repetida)\n",
    "                if df.iloc[i, 1] == 1:\n",
    "                    verify[i] = 1                           # Adição de valores à matriz verify (adiciona 1 para spam)\n",
    "                elif df.iloc[i, 1] == 0:\n",
    "                    verify[i] = -1                          # Adição de valores à matriz verify (adiciona -1 para ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    def __init__(self, l_rate, n_iter):\n",
    "        self.l_rate = l_rate\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def classify(self, data, verify):\n",
    "        self.errors_list = []\n",
    "        probs = np.zeros(data.shape[0])\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            errors = 0\n",
    "            mail_count = 0\n",
    "            for mail, target in zip(data, verify):\n",
    "                prediction = self.predict(mail)\n",
    "                update = self.l_rate * (target - prediction)\n",
    "                if update != 0:\n",
    "                    weight[1:] += update * mail\n",
    "                    weight[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "                probs[mail_count] = prediction\n",
    "                mail_count += 1\n",
    "            self.errors_list.append(errors)\n",
    "        return probs\n",
    "\n",
    "    def net_input(self, mail):\n",
    "        return np.dot(mail, weight[1:]) + weight[0]\n",
    "\n",
    "    def predict(self, mail):\n",
    "        return np.where(self.net_input(mail) >= 0.0, 1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nFicheiro\nNúmero de linhas analisadas: 5572\nNúmero de palavras existentes (sem repetição): 3801\nNúmero de mensagens classificadas como spam: 0\nNúmero de mensagens classificadas como ham: 0\n\nAlgoritmo Perceptrão\nNúmero de mensagens classificadas como spam: 2106\nNúmero de mensagens classificadas como ham: 3466\n\nPrecisão do algoritmo: 0.000 %\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    vocabulary = {}\n",
    "    train(\"Treino\")\n",
    "    weight = np.zeros(1 + data.shape[1])\n",
    "    P = Perceptron(0.01, 20)\n",
    "    P.classify(data, verify)\n",
    "\n",
    "    generate(\"Treino\")\n",
    "    P = Perceptron(0, 1)\n",
    "    classification = P.classify(data, verify)\n",
    " \n",
    "    print(\"\\nFicheiro\\nNúmero de linhas analisadas: {}\".format(data.shape[0]))\n",
    "    print(\"Número de palavras existentes (sem repetição): {}\".format(data.shape[1]))\n",
    "    print(\"Número de mensagens classificadas como spam: {}\".format(sum(verify == 1)))\n",
    "    print(\"Número de mensagens classificadas como ham: {}\".format(sum(verify == -1)))\n",
    "\n",
    "    print(\"\\nAlgoritmo Perceptrão\\nNúmero de mensagens classificadas como spam: {}\".format(sum(classification == 1)))\n",
    "    print(\"Número de mensagens classificadas como ham: {}\".format(sum(classification == -1)))\n",
    "    print(\"\\nPrecisão do algoritmo: {:0.3f} %\".format(sum(classification == verify) / data.shape[1] * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}