{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas x Colunas (5572, 2) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "      <th>Mensagem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Status                                           Mensagem\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DATA SETS ---------\n",
    "df = pd.read_csv(\"spam.csv\", encoding = \"latin-1\", usecols=[\"v1\", \"v2\"])\n",
    "\n",
    "## TRANSFORMS\n",
    "df.columns = [\"Status\", \"Mensagem\"]\n",
    "\n",
    "print(\"Linhas x Colunas\", df.shape, \"\\n\") \n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Luis\n",
      "[nltk_data]     Carlos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nltk.data.find(\"words\")\n",
    "except LookupError:\n",
    "    nltk.download(\"words\") \n",
    "set_words = set(words.words())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go until jurong point  crazy   available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar    joking wif u oni</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u dun say so early hor    u c already then say</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah i don t think he goes to usf  he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem Status\n",
       "0  go until jurong point  crazy   available only ...      0\n",
       "1                      ok lar    joking wif u oni         0\n",
       "2  free entry in 2 a wkly comp to win fa cup fina...      1\n",
       "3  u dun say so early hor    u c already then say         0\n",
       "4  nah i don t think he goes to usf  he lives aro...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Mensagem'] = df['Mensagem'].str.replace('\\W', ' ') # Limpa a pontuação\n",
    "df['Mensagem'] = df['Mensagem'].str.lower()  #Transforma tudo em letra pequena\n",
    "\n",
    "df = df[[\"Mensagem\", \"Status\"]]\n",
    "\n",
    "df['Status'] = df['Status'].str.replace('spam', '1') # Limpa o subject\n",
    "df['Status'] = df['Status'].str.replace('ham', '0') # Limpa o subject\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    def __init__(self, learningRate, numberIterations): #construtor do perceptron\n",
    "        self.learningRate = learningRate\n",
    "        self.numberIterations = numberIterations #AKA EPochs/Epocas\n",
    "\n",
    "    def classificar(self, data, verify):\n",
    "        self.listaErros = []\n",
    "\n",
    "        probs = np.zeros(data.shape[0])\n",
    "\n",
    "        for i in range(self.numberIterations):\n",
    "            erros = 0\n",
    "            mail_count = 0\n",
    "\n",
    "            for mail, target in zip(data, verify):\n",
    "                prediction = self.predict(mail)\n",
    "                update = self.learningRate * (target - prediction)\n",
    "\n",
    "                if update != 0:\n",
    "                    weight[1:] += update * mail\n",
    "                    weight[0] += update\n",
    "\n",
    "                erros += int(update != 0.0)\n",
    "\n",
    "                probs[mail_count] = prediction\n",
    "\n",
    "                mail_count += 1\n",
    "\n",
    "            self.listaErros.append(erros)\n",
    "\n",
    "        return probs\n",
    "\n",
    "    def net_input(self, mail):\n",
    "        return np.dot(mail, weight[1:]) + weight[0]\n",
    "\n",
    "    def predict(self, mail):\n",
    "        return np.where(self.net_input(mail) >= 0.0, 1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(ficheiro):                                   # Função generate - Gera as matrizes data e verify\n",
    "    global data                                           # Variável data definida como global\n",
    "    data = np.zeros((df.shape[0], len(vocabulary)))        # Criação de uma matriz com número de linhas igual ao número de linhas do ficheiro e com número de colunas igual ao número de palavras (sem repetição) existentes no vocabulário\n",
    "\n",
    "    global verify                                           # Variável verify definida como global\n",
    "    verify = np.zeros(df.shape[0])                          # Criação de uma matriz com número de linhas igual ao número de linhas do ficheiro e com uma coluna\n",
    "\n",
    "    for i in range(df.shape[0]):                          # Ciclo que corre todas as linhas do ficheiro\n",
    "        email = df.iloc[i, 0].split()                        # ----------------------------------------------------------\n",
    "\n",
    "        for word in email:                                  # Ciclo que corre todas as palavras de uma mensagem\n",
    "            if word.lower() in vocabulary:                  # Verificação da existência da palavra no dicionário vocabulary\n",
    "                data[i, vocabulary[word]] += 1              # Adição de valores à matriz data (+1 no índice da palavra que foi repetida)\n",
    "\n",
    "                if df.iloc[i, 1] == '1':\n",
    "                    verify[i] = 1                           # Adição de valores à matriz verify (adiciona 1 para spam)\n",
    "\n",
    "                elif df.iloc[i, 1] == '0':\n",
    "                    verify[i] = -1                          # Adição de valores à matriz verify (adiciona -1 para ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de Treino\n",
      "0    3379\n",
      "1     521\n",
      "Name: Status, dtype: int64\n",
      "Linhas  3900\n",
      "\n",
      "Dados de Teste\n",
      "0    724\n",
      "1    112\n",
      "Name: Status, dtype: int64\n",
      "Linhas  836\n",
      "\n",
      "Dados de Verificação\n",
      "0    722\n",
      "1    114\n",
      "Name: Status, dtype: int64\n",
      "Linhas  836\n"
     ]
    }
   ],
   "source": [
    "#Divisão em Sets\n",
    "train, validate, test = np.split(df.sample(frac=1, random_state=42), [int(.7*len(df)), int(.85*len(df))])   #Split aos 70 para criar o grupo de treino, e aos 85 para criar o grupo de teste e validação\n",
    "\n",
    "\n",
    "#Resultado dos Splits\n",
    "print(\"Dados de Treino\")\n",
    "print(train['Status'].value_counts())\n",
    "print(\"Linhas \", len(train.index))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Dados de Teste\")\n",
    "print(test['Status'].value_counts())\n",
    "print(\"Linhas \", len(test.index))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Dados de Verificação\")\n",
    "print(validate['Status'].value_counts())\n",
    "print(\"Linhas \", len(validate.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VALIDAÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ficheiro):                                   # Função train - Recebe um ficheiro e cria um dicionário (vocabulary) das palavras usadas\n",
    "    for i in range(df.shape[0]):                          # Ciclo que corre todas as mensagens do ficheiro\n",
    "        email = df.iloc[i, 0].split()                   # Mensagem separada por palavras\n",
    "\n",
    "        for word in email:                                  # Ciclo que corre todas as palavras de uma mensagem\n",
    "            if word.lower() not in vocabulary and word.lower() in set_words: # Verificação da existência da palavra no dicionário vocabulary e no set set_words\n",
    "                vocabulary[word] = len(vocabulary)          # Atribuição de uma posição à palavra analisada no dicionário vocabulary\n",
    "    generate(str(ficheiro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de Linhas:  5572\n",
      "0    4825\n",
      "1     747\n",
      "Name: Status, dtype: int64\n",
      "Algoritmo\n",
      "\n",
      "Número de mensagens classificadas como spam:  744\n",
      "Número de mensagens classificadas como ham:  4828\n",
      "\n",
      "Precisão do algoritmo:  98.63603732950466\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    vocabulary = {}\n",
    "    train(df)\n",
    "    weight = np.zeros(1 + data.shape[1])\n",
    "    P = Perceptron(1, 10)\n",
    "    P.classificar(data, verify)\n",
    "\n",
    "    generate(df)\n",
    "    P = Perceptron(0, 1)\n",
    "    classification = P.classificar(data, verify)\n",
    " \n",
    "    print(\"Total de Linhas: \", df.shape[0])\n",
    "    print(df['Status'].value_counts())\n",
    "\n",
    "    print(\"Algoritmo\")\n",
    "    print(\"\\nNúmero de mensagens classificadas como spam: \", (sum(classification == 1)))\n",
    "    print(\"Número de mensagens classificadas como ham: \", (sum(classification == -1)))\n",
    "    print(\"\\nPrecisão do algoritmo: \", (sum(classification == verify) / data.shape[0] * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}