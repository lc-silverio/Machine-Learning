{
 "cells": [
  {
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import nltk\r\n",
    "from nltk.corpus import words"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "source": [
    "## DATA SETS ---------\n",
    "df = pd.read_csv(\"spam.csv\", encoding = \"latin-1\", usecols=[\"v1\", \"v2\"])\n",
    "\n",
    "## TRANSFORMS\n",
    "df.columns = [\"Status\", \"Mensagem\"]\n",
    "\n",
    "print(\"Linhas x Colunas\", df.shape, \"\\n\") \n",
    "df.head() "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Linhas x Colunas (5572, 2) \n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Status                                           Mensagem\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Status</th>\n      <th>Mensagem</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "source": [
    "try:\n",
    "    nltk.data.find(\"words\")\n",
    "except LookupError:\n",
    "    nltk.download(\"words\") \n",
    "set_words = set(words.words())    "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Luis\n[nltk_data]     Carlos\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ]
  },
  {
   "source": [
    "df['Mensagem'] = df['Mensagem'].str.replace('\\W', ' ') # Limpa a pontuação\n",
    "df['Mensagem'] = df['Mensagem'].str.replace('subject', ' ') # Limpa o subject\n",
    "df['Mensagem'] = df['Mensagem'].str.lower()  #Transforma tudo em letra pequena\n",
    "\n",
    "df = df[[\"Mensagem\", \"Status\"]]\n",
    "\n",
    "df['Status'] = df['Status'].str.replace('spam', '1') # Limpa o subject\n",
    "df['Status'] = df['Status'].str.replace('ham', '0') # Limpa o subject\n",
    "\n",
    "df.head()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            Mensagem Status\n",
       "0  go until jurong point  crazy   available only ...      0\n",
       "1                      ok lar    joking wif u oni         0\n",
       "2  free entry in 2 a wkly comp to win fa cup fina...      1\n",
       "3  u dun say so early hor    u c already then say         0\n",
       "4  nah i don t think he goes to usf  he lives aro...      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mensagem</th>\n      <th>Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>go until jurong point  crazy   available only ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ok lar    joking wif u oni</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>u dun say so early hor    u c already then say</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>nah i don t think he goes to usf  he lives aro...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    def __init__(self, learningRate, numberIterations): #construtor do perceptron\n",
    "        self.learningRate = learningRate\n",
    "        self.numberIterations = numberIterations #AKA EPochs/Epocas\n",
    "\n",
    "    def classificar(self, data, verify):\n",
    "        self.listaErros = []\n",
    "\n",
    "        probs = np.zeros(data.shape[0])\n",
    "\n",
    "        for i in range(self.numberIterations):\n",
    "            erros = 0\n",
    "            mail_count = 0\n",
    "\n",
    "            for mail, target in zip(data, verify):\n",
    "                prediction = self.predict(mail)\n",
    "                update = self.learningRate * (target - prediction)\n",
    "\n",
    "                if update != 0:\n",
    "                    weight[1:] += update * mail\n",
    "                    weight[0] += update\n",
    "\n",
    "                erros += int(update != 0.0)\n",
    "\n",
    "                probs[mail_count] = prediction\n",
    "\n",
    "                mail_count += 1\n",
    "\n",
    "            self.listaErros.append(erros)\n",
    "\n",
    "        return probs\n",
    "\n",
    "    def net_input(self, mail):\n",
    "        return np.dot(mail, weight[1:]) + weight[0]\n",
    "\n",
    "    def predict(self, mail):\n",
    "        return np.where(self.net_input(mail) >= 0.0, 1, -1)\n"
   ]
  },
  {
   "source": [
    "def generate(ficheiro):                                   # Função generate - Gera as matrizes data e verify\n",
    "    global data                                           # Variável data definida como global\n",
    "    data = np.zeros((df.shape[0], len(vocabulary)))        # Criação de uma matriz com número de linhas igual ao número de linhas do ficheiro e com número de colunas igual ao número de palavras (sem repetição) existentes no vocabulário\n",
    "\n",
    "    global verify                                           # Variável verify definida como global\n",
    "    verify = np.zeros(df.shape[0])                          # Criação de uma matriz com número de linhas igual ao número de linhas do ficheiro e com uma coluna\n",
    "\n",
    "    for i in range(df.shape[0]):                          # Ciclo que corre todas as linhas do ficheiro\n",
    "        email = df.iloc[i, 0].split()                        # ----------------------------------------------------------\n",
    "\n",
    "        for word in email:                                  # Ciclo que corre todas as palavras de uma mensagem\n",
    "            if word.lower() in vocabulary:                  # Verificação da existência da palavra no dicionário vocabulary\n",
    "                data[i, vocabulary[word]] += 1              # Adição de valores à matriz data (+1 no índice da palavra que foi repetida)\n",
    "\n",
    "                if df.iloc[i, 1] == '1':\n",
    "                    verify[i] = 1                           # Adição de valores à matriz verify (adiciona 1 para spam)\n",
    "\n",
    "                elif df.iloc[i, 1] == '0':\n",
    "                    verify[i] = -1                          # Adição de valores à matriz verify (adiciona -1 para ham)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'remainingGroup' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-1f7050f5f2fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mremaingGroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandomSample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msampleSize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremainingGroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaingGroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mremainingData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mverify_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremainingGroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaingGroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mremainingData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'remainingGroup' is not defined"
     ]
    }
   ],
   "source": [
    "#Divisão em Sets\n",
    "randomSample = df.sample(frac=1, random_state=666) # Faz suffle da tabela - frac é a fração dos dados a usar (0,0 a 1,0) - random-state = (int) é a seed que o sistema vai usar como \"fator de entropia\" para gerar o \"random\"\n",
    "\n",
    "# Definir o percentagem de dados a usar (0 a 1)\n",
    "sampleSize = round(len(randomSample) * 0.8)\n",
    "\n",
    "# Criação do grupo de teste e treino\n",
    "trainGroup = randomSample[:sampleSize].reset_index(drop=True) #Faz splice dos dados com base no <inserir nome> que serve como indicador da percentagem de dados a usar. neste caso os primeiros 80% da tabela - reset_index faz reset ao indice da tabela\n",
    "\n",
    "remainingData = 1 - sampleSize\n",
    "remaingGroup = randomSample[sampleSize:].reset_index(drop=True)\n",
    "\n",
    "test_set = remainingGroup[:round(len(remaingGroup)*remainingData)]\n",
    "verify_set = remainingGroup[round(len(remaingGroup)*remainingData):]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Dados de Treino\")\n",
    "print(trainGroup['Status'].value_counts())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Dados de Teste\")\n",
    "print(test_set['Status'].value_counts())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "print(\"Dados de Verificação\")\n",
    "print(verify_set['Status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VALIDAÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ficheiro):                                   # Função train - Recebe um ficheiro e cria um dicionário (vocabulary) das palavras usadas\n",
    "    for i in range(df.shape[0]):                          # Ciclo que corre todas as mensagens do ficheiro\n",
    "        email = df.iloc[i, 0].split()                   # Mensagem separada por palavras\n",
    "\n",
    "        for word in email:                                  # Ciclo que corre todas as palavras de uma mensagem\n",
    "            if word.lower() not in vocabulary and word.lower() in set_words: # Verificação da existência da palavra no dicionário vocabulary e no set set_words\n",
    "                vocabulary[word] = len(vocabulary)          # Atribuição de uma posição à palavra analisada no dicionário vocabulary\n",
    "    generate(str(ficheiro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total de Linhas:  5572\n0    4825\n1     747\nName: Status, dtype: int64\nAlgoritmo\n\nNúmero de mensagens classificadas como spam:  744\nNúmero de mensagens classificadas como ham:  4828\n\nPrecisão do algoritmo:  98.63603732950466\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    vocabulary = {}\n",
    "    train(df)\n",
    "    weight = np.zeros(1 + data.shape[1])\n",
    "    P = Perceptron(1, 10)\n",
    "    P.classificar(data, verify)\n",
    "\n",
    "    generate(df)\n",
    "    P = Perceptron(0, 1)\n",
    "    classification = P.classificar(data, verify)\n",
    " \n",
    "    print(\"Total de Linhas: \", df.shape[0])\n",
    "    print(df['Status'].value_counts())\n",
    "\n",
    "    print(\"Algoritmo\")\n",
    "    print(\"\\nNúmero de mensagens classificadas como spam: \", (sum(classification == 1)))\n",
    "    print(\"Número de mensagens classificadas como ham: \", (sum(classification == -1)))\n",
    "    print(\"\\nPrecisão do algoritmo: \", (sum(classification == verify) / data.shape[0] * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}